{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846497b0-e864-459a-9ec3-d605dbba7cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Wei_lai/NLP/Mine_Project/NLP/Mine_Project/AllenNLP/Learning/Baseline_Allennlp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfb6ec6-a812-4f29-a317-d8e35d3cb976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/allennlp/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94ee1ab-3133-4746-a6e0-24f0a0855dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021f6164-ae9a-4971-a602-96cebb01849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([32, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796f9d81-c62c-40f5-8d56-e26c97b7de43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2348,  0.1244],\n",
       "        [ 1.7269, -0.9430],\n",
       "        [-0.8077, -1.5160],\n",
       "        [-0.3832, -1.8998],\n",
       "        [-0.5702,  0.6110],\n",
       "        [-1.1503,  0.4799],\n",
       "        [ 0.7822, -0.1931],\n",
       "        [ 0.4841, -0.1825],\n",
       "        [-0.5658,  0.9536],\n",
       "        [-0.0365,  0.8366],\n",
       "        [-0.6191, -0.4360],\n",
       "        [ 1.4674, -0.2152],\n",
       "        [-0.5249,  0.4626],\n",
       "        [-0.0106,  0.8740],\n",
       "        [-0.4973,  0.0867],\n",
       "        [ 0.6949,  0.5408],\n",
       "        [-0.5121,  0.4360],\n",
       "        [-1.8748,  1.1992],\n",
       "        [-0.2138,  0.5512],\n",
       "        [-1.0616,  2.4117],\n",
       "        [ 0.2825,  0.7582],\n",
       "        [ 0.8356,  1.2017],\n",
       "        [-1.3648,  0.2328],\n",
       "        [-0.9843, -0.5266],\n",
       "        [-2.7932, -1.6551],\n",
       "        [ 0.2871, -1.0084],\n",
       "        [ 0.7000, -0.2029],\n",
       "        [ 1.0045,  0.8946],\n",
       "        [ 0.0223,  1.2838],\n",
       "        [-0.5997,  0.5784],\n",
       "        [ 1.1471,  0.2472],\n",
       "        [ 0.3807, -1.4527]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6607525f-8e9a-4600-ad1c-f3144f574aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ef7e8c-e77c-4e1b-8cd2-28830356f1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0535,  0.0878, -0.1278,  ..., -0.0708,  0.0949, -0.1019],\n",
       "        [-0.1511, -0.0487, -0.0280,  ...,  0.1568,  0.1341, -0.1569],\n",
       "        [ 0.0501, -0.0342,  0.0705,  ...,  0.0032,  0.0279, -0.0744],\n",
       "        ...,\n",
       "        [ 0.1494,  0.1501,  0.0781,  ...,  0.1032, -0.0025,  0.0320],\n",
       "        [-0.0534,  0.0420, -0.0177,  ...,  0.0968, -0.0842, -0.1072],\n",
       "        [-0.0533,  0.1482, -0.0358,  ..., -0.0474,  0.0328, -0.0884]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_embeddings = 100\n",
    "embedding_dim = 128\n",
    "trainable = True\n",
    "weight = torch.FloatTensor(num_embeddings, embedding_dim)\n",
    "my_weight = torch.nn.Parameter(weight, requires_grad=trainable)\n",
    "torch.nn.init.xavier_uniform_(my_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cfd0b0-ef1b-49d7-aa6f-0c7f3e5e8426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.complex64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.2, 3j]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e34b5-f5a2-45ac-a87e-7600af974226",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.FloatTensor(num_embeddings, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9053796e-13ad-487d-b4c1-3c09c0b7e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_r = torch.randn([3,4,5])\n",
    "a_i = torch.randn([3,4,5])\n",
    "a = a_r + 1j * a_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cee97808-e472-4726-a530-d5077adaaf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.complex64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af869bba-ca48-4e8b-ada3-d76fa05e555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.unsqueeze(-1)\n",
    "b = a @ a.permute(0, 1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91900b1e-062a-45ff-b6c7-caa8ecb21206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d354a2-f1c7-46eb-8f0b-8a886fa0c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.mean(b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205d13c3-3aa0-4ce9-b701-a5c6341c1d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b974a7-23b9-4b4c-9813-9a09bfa3dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_r = torch.randn_like(V[0])\n",
    "P_i = torch.randn_like(V[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e50e7c7-ccc3-473e-8b94-45bf8e943d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = P_r + 1j * P_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ae75257-6de8-443d-be14-7094f13629cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P\n",
    "res = P @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "478b4821-f467-4d40-b6a5-a7d1e8336a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a026803-7434-46cb-95d4-527d2f9f7c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8016, 6.0701, 0.8210, 2.6973, 1.6666])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(res[0]).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "826a2787-58f4-4d33-b790-f5fb71fb0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [torch.diagonal(W).abs().unsqueeze(0) for W in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a2b9c42-e180-41ec-b0cb-a2ea89d959fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.cat(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65fd31f8-195e-4c03-b8e2-c8b60439940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1d4c590-349a-401f-8704-1e64ccbdcdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [torch.diagonal(W).abs() for W in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a45badb0-5fb7-4675-be4e-26e8327ae93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2.8016, 6.0701, 0.8210, 2.6973, 1.6666]),\n",
       " tensor([2.1187, 3.3910, 0.7752, 2.6626, 2.1669]),\n",
       " tensor([2.8530, 3.1495, 1.5360, 2.0433, 2.6876])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b7c96-5a4c-40a4-8198-2a82769f5e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b4ced-95db-4efe-81a2-8872269e32ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6862f15-b31d-4378-8f04-1a334ffe60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.mean(b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc60c42d-9928-4a3d-b41b-421f3cc95aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [torch.trace(batch).abs() for batch in V]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32489dc2-23aa-4238-a3fe-7409fea5d95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.5455), tensor(3.3538), tensor(1.8823)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4759b7e4-fef5-46bf-a5f4-d8b7ad973ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-0.3742-0.3969j), tensor(-0.4802-3.3193j), tensor(-0.9215-1.6413j)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d154c6eb-a2b4-4b32-b115-e1707aca4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = V.to('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a87a058-63ac-4c1b-a713-73bf9bad7589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82f56f99-ed1e-4f68-8bf0-e2be67cac669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "502a533a-5dca-47eb-86d0-e61922cfd4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(V.device).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fd2c421-ecdf-444f-8ba5-93d9bf432b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7660+0.5684j,  1.2131-0.8928j,  0.0606-1.0966j, -0.4224-0.2930j,\n",
       "          -0.4386+1.1390j],\n",
       "         [ 1.2131-0.8928j, -0.2809-2.2389j, -0.1463-0.0700j, -1.1413-0.0202j,\n",
       "           0.2129+1.3358j],\n",
       "         [ 0.0606-1.0966j, -0.1463-0.0700j, -0.9910+0.7736j, -0.9320-0.1822j,\n",
       "          -0.4855-0.6426j],\n",
       "         [-0.4224-0.2930j, -1.1413-0.0202j, -0.9320-0.1822j,  0.6579+0.7890j,\n",
       "           1.1143-0.4803j],\n",
       "         [-0.4386+1.1390j,  0.2129+1.3358j, -0.4855-0.6426j,  1.1143-0.4803j,\n",
       "          -0.5263-0.2891j]],\n",
       "\n",
       "        [[ 1.2514-0.6646j,  0.2043+1.0286j, -1.1268+0.5360j, -0.1269-1.6964j,\n",
       "          -0.5469+1.1794j],\n",
       "         [ 0.2043+1.0286j, -0.2487-0.3728j, -0.3410-1.2807j,  1.3732+0.5940j,\n",
       "          -0.5359-1.2647j],\n",
       "         [-1.1268+0.5360j, -0.3410-1.2807j,  1.0851-0.2500j, -0.0201+1.5444j,\n",
       "           0.1573-0.9658j],\n",
       "         [-0.1269-1.6964j,  1.3732+0.5940j, -0.0201+1.5444j, -1.8497-0.6755j,\n",
       "           1.1876+0.9082j],\n",
       "         [-0.5469+1.1794j, -0.5359-1.2647j,  0.1573-0.9658j,  1.1876+0.9082j,\n",
       "          -0.7183-1.3564j]],\n",
       "\n",
       "        [[ 0.1412+0.1783j, -0.2296+0.3456j,  0.3992+0.5899j, -0.3320+0.2109j,\n",
       "           0.0094-0.5569j],\n",
       "         [-0.2296+0.3456j, -0.4250-0.6039j, -0.2709-0.3648j,  0.0590-0.2494j,\n",
       "           0.0677+1.0142j],\n",
       "         [ 0.3992+0.5899j, -0.2709-0.3648j, -1.8413-0.8790j,  0.4544-0.4902j,\n",
       "           0.5430+0.5541j],\n",
       "         [-0.3320+0.2109j,  0.0590-0.2494j,  0.4544-0.4902j,  0.0948+0.8757j,\n",
       "          -0.0596+0.1864j],\n",
       "         [ 0.0094-0.5569j,  0.0677+1.0142j,  0.5430+0.5541j, -0.0596+0.1864j,\n",
       "           1.1088-1.2124j]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "315e7ecb-e7ab-428f-b138-c0bb1c810e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13110a4d-663c-4431-8cae-77299745fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.permute(0, 1, 3, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55c182-f757-4808-8520-d511d192cdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e1458-9028-4506-94f0-5fa999c31cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec3414-a966-4209-af6a-ff2280e9a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_bert.jsonnet --include-package myclassifier -s ./result/sst5_bert -f --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8537705-0add-41e4-8ff3-53f8c7196d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fddc2e-d4c8-479f-834b-14e89fac25c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b83c41-5a31-4693-8a1f-a1f4dbc60ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 100\n",
    "embedding_dim = 128\n",
    "trainable = True\n",
    "weight = torch.FloatTensor(num_embeddings, embedding_dim)\n",
    "my_weight = torch.nn.Parameter(weight, requires_grad=trainable)\n",
    "torch.nn.init.xavier_uniform_(my_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53227ac4-cb64-4976-9132-fbbd98f3ebeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31460b4-0268-4339-a761-9f33e1b0fbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/Wei_lai/NLP/Mine_Project/NLP/Mine_Project/AllenNLP/Learning/Baseline_Allennlp'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167dffed-9290-4ec3-bcd7-ad748ff0fb66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d7305-4790-4ab1-a224-1f4bca62abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_cnn.jsonnet --include-package myclassifier -s ./result/mytrain2 -f --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374b231-dd35-48a4-ae02-e7284e88e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_cnn.jsonnet --include-package myclassifier -s ./result/cr_textcnn -f --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da708d39-0411-4c97-b88d-2ff7a0249b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_elmo.jsonnet --include-package myclassifier -s ./result/sst_emlo -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4dbc46-0896-4c36-8aba-6a2b0d8225e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_bert.jsonnet --include-package myclassifier -s ./result/subj_bert -f --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3516b-2e23-48b2-a33f-7ec1ed100bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_elmo.jsonnet --include-package myclassifier -s ./result/sst_emlo_test -f --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f00269-bc34-400d-a751-d499810c8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_elmo.jsonnet --include-package myclassifier -s ./result/subj_emlo_test -f --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4b371-bed5-4063-80f4-92b09b5e79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train config/text_classifier_complexcnn.jsonnet --include-package myclassifier -s ./result/cr_complexcnn -f --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27662b08-124d-4c0c-9c52-468986da04ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d33b35-df72-4557-9c8a-439f7352f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allennlp train -s result/allennlp imdb_baseline.jsonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489bda97-876f-496f-aba8-ae6544f630d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path: 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/imdb/train.jsonl',\n",
    "  validation_data_path: 'https://s3-us-west-2.amazonaws.com/allennlp/datasets/imdb/dev.jsonl',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e9cf5-7a76-4394-8e0c-354cf7356325",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path: 'https://levynlp.oss-cn-hangzhou.aliyuncs.com/datasets/SST/Binary/sentiment-dev',\n",
    "validation_data_path: 'https://levynlp.oss-cn-hangzhou.aliyuncs.com/datasets/SST/Binary/sentiment-train',\n",
    "\n",
    "train_data_path: '/workspace/Wei_lai/NLP/data/SST/Binary/sentiment-train',\n",
    "validation_data_path: '/workspace/Wei_lai/NLP/data/SST/Binary/sentiment-dev',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1b8c3-b542-4ed4-ad5c-0dec3e0dea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"options_file\": \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\",\n",
    "\"weight_file\": \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\",\n",
    "\"dropout\": 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1aedb3-f415-48dc-8d82-f92422a1e9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8950161-08c3-4d40-a821-4f06e40e7358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9623ccb-5091-41e5-8796-1a026ae67cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders.elmo_token_embedder import ElmoTokenEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707437d4-ab30-4fb2-b121-0b0b7cfe8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.text_field_embedders.basic_text_field_embedder import BasicTextFieldEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc50e2a4-6cd0-4b80-aa89-74a9174dfc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = BasicTextFieldEmbedder(token_embedders={\"tokens\": ElmoTokenEmbedder()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "735d362c-ce7a-4d30-9704-dd489b7a092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "token_tensor = {\"elmo\": {\"tokens\": torch.LongTensor([[1, 3, 2, 9, 4, 3]])}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4233288a-a02b-417c-ba1e-ba4988aba966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "deb195ca-31b4-42e2-b8a5-f762eb318505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5752e246-5b5b-471f-84bd-c5d62691da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcabc19e-f8b1-49c8-b580-abcc5e32b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indexer = ELMoTokenCharactersIndexer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d3ad8b2-4a56-43e6-aa26-bcde95517db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from allennlp.data import Token, Vocabulary, TokenIndexer, Tokenizer\n",
    "from allennlp.data.fields import ListField, TextField\n",
    "from allennlp.data.token_indexers import (\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data.tokenizers import (\n",
    "    CharacterTokenizer,\n",
    "    PretrainedTransformerTokenizer,\n",
    "    SpacyTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    ")\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.nn import util as nn_util\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f85c636-434f-4a37-924d-5eec6ad17822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With single id indexer: {'tokens': {'elmo_tokens': tensor([[259,  85, 105, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 116, 112, 110, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 117, 102, 121, 117, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261]])}}\n"
     ]
    }
   ],
   "source": [
    "text = \"This is some text .\"\n",
    "tokenizer: Tokenizer = WhitespaceTokenizer()\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_indexer = ELMoTokenCharactersIndexer()\n",
    "text_field = TextField(tokens, {\"tokens\": token_indexer})\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_tokens_to_namespace(\n",
    "    [\"This\", \"is\", \"some\", \"text\", \".\"], namespace=\"token_vocab\"\n",
    ")\n",
    "# In order to convert the token strings into integer ids, we need to tell the\n",
    "# TextField what Vocabulary to use.\n",
    "text_field.index(vocab)\n",
    "\n",
    "# We typically batch things together when making tensors, which requires some\n",
    "# padding computation.  Don't worry too much about the padding for now.\n",
    "padding_lengths = text_field.get_padding_lengths()\n",
    "\n",
    "tensor_dict = text_field.as_tensor(padding_lengths)\n",
    "# This output is pretty nested and might look complex.  The reason it is so\n",
    "# nested is that we need to (1) align each indexer with a corresponding\n",
    "# embedder in the model, and (2) pass a dictionary of arguments to the\n",
    "# embedder by name.  This will be more clear when we get to the embedder.\n",
    "print(\"With single id indexer:\", tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c37b1d-2372-46cc-a561-fcc766e4bf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': {'elmo_tokens': tensor([[259,  85, 105, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261],\n",
       "          [259, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261],\n",
       "          [259, 116, 112, 110, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261],\n",
       "          [259, 117, 102, 121, 117, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261],\n",
       "          [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "           261, 261, 261, 261, 261, 261, 261, 261]])}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42861eee-01be-4f8f-871d-fb7513b590e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18347ccf-4cce-40d3-be1b-e3d923347a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "602d4b94-8b71-4836-bed9-b07c63555c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embedder = embedder._token_embedders['elmo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c9af3-0045-49a5-9408-127b92d4a1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d51b914a-5c6d-4121-8147-a92ebb4d29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo_embedder(tensor_dict['tokens']['elmo_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac9b16-7f3e-408f-a2fc-74a996c426c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "token_tensor = {\"elmo\": {\"tokens\": torch.LongTensor([[1, 3, 2, 9, 4, 3]])}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ff0bd-6f5c-4fba-a3bf-3ac7dc8acb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = BasicTextFieldEmbedder(token_embedders={\"tokens\": ElmoTokenEmbedder()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84f94bb8-8a0f-403e-99b6-f028dc3d1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c86abab-834f-4156-85b0-a2516b3c27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tensor_dict['tokens']['elmo_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2166b23f-0283-4ed8-8f15-8aaa7ce56fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.nn.util import get_text_field_mask\n",
    "\n",
    "mask = get_text_field_mask(tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6560c015-a076-428d-ac78-86ad1de7bfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elmo_tokens': tensor([[259,  85, 105, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 116, 112, 110, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 117, 102, 121, 117, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261]])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dict['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cae84a32-772e-428e-8fc3-5dcd54609e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_tokens = tensor_dict['tokens']['elmo_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c606c446-5d0d-4748-b6a8-0f1e411c3915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_tokens.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8fa09622-d92d-4d3f-bed2-f33a46cf9bea",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43melmo_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43melmo_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/allennlp/modules/token_embedders/elmo_token_embedder.py:101\u001b[0m, in \u001b[0;36mElmoTokenEmbedder.forward\u001b[0;34m(self, elmo_tokens, word_inputs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, elmo_tokens: torch\u001b[38;5;241m.\u001b[39mTensor, word_inputs: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    # Parameters\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m        `(batch_size, timesteps, embedding_dim)`\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     elmo_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_elmo\u001b[49m\u001b[43m(\u001b[49m\u001b[43melmo_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     elmo_representations \u001b[38;5;241m=\u001b[39m elmo_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melmo_representations\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_projection:\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/allennlp/modules/elmo.py:186\u001b[0m, in \u001b[0;36mElmo.forward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     reshaped_word_inputs \u001b[38;5;241m=\u001b[39m word_inputs\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# run the biLM\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m bilm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_elmo_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshaped_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshaped_word_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    187\u001b[0m layer_activations \u001b[38;5;241m=\u001b[39m bilm_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivations\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    188\u001b[0m mask_with_bos_eos \u001b[38;5;241m=\u001b[39m bilm_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/allennlp/modules/elmo.py:594\u001b[0m, in \u001b[0;36m_ElmoBiLm.forward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    592\u001b[0m         type_representation \u001b[38;5;241m=\u001b[39m token_embedding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 594\u001b[0m     token_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_token_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     mask \u001b[38;5;241m=\u001b[39m token_embedding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    596\u001b[0m     type_representation \u001b[38;5;241m=\u001b[39m token_embedding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/allennlp/modules/elmo.py:337\u001b[0m, in \u001b[0;36m_ElmoCharacterEncoder.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Add BOS/EOS\u001b[39;00m\n\u001b[1;32m    336\u001b[0m mask \u001b[38;5;241m=\u001b[39m (inputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 337\u001b[0m character_ids_with_bos_eos, mask_with_bos_eos \u001b[38;5;241m=\u001b[39m \u001b[43madd_sentence_boundary_token_ids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beginning_of_sentence_characters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_of_sentence_characters\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# the character id embedding\u001b[39;00m\n\u001b[1;32m    342\u001b[0m max_chars_per_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar_cnn\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_characters_per_token\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.8/site-packages/allennlp/nn/util.py:1635\u001b[0m, in \u001b[0;36madd_sentence_boundary_token_ids\u001b[0;34m(tensor, mask, sentence_begin_token, sentence_end_token)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_sentence_boundary_token_ids\u001b[39m(\n\u001b[1;32m   1602\u001b[0m     tensor: torch\u001b[38;5;241m.\u001b[39mTensor, mask: torch\u001b[38;5;241m.\u001b[39mBoolTensor, sentence_begin_token: Any, sentence_end_token: Any\n\u001b[1;32m   1603\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mBoolTensor]:\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;124;03m    Add begin/end of sentence tokens to the batch of sentences.\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;124;03m    Given a batch of sentences with size `(batch_size, timesteps)` or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m        marking the beginning and end of the sentence.\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1635\u001b[0m     sequence_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m   1636\u001b[0m     tensor_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1637\u001b[0m     new_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tensor_shape)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "elmo_embedder(elmo_tokens.reshape(-1), word_inputs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24949e5b-f7b4-47d8-8fd4-cb1f02b021a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c6c66980-0e7f-42ad-964c-c69f7cc4b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo_embedder(tokens, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83e50b-833c-4984-b183-406904a0cd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
